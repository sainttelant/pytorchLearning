{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy 前后神经网络\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "\n",
    "# N是批量大小; D_in是输入维度;\n",
    "# 49/5000 H是隐藏的维度; D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建随机输入和输出数据\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# 随机初始化权重\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 前向传递：计算预测值y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "\n",
    "    # 计算和打印损失loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # 反向传播，计算w1和w2对loss的梯度\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "\n",
    "    # 更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "张量（Tensor）：PyTorch的tensor在概念上与numpy的array相同： \n",
    "tensor是一个n维数组，PyTorch提供了许多函数用于操作这些张量。任何希望使用NumPy执行的计算也可以使用PyTorch的tensor来完成，\n",
    "可以认为它们是科学计算的通用工具。\n",
    "\n",
    "与Numpy不同，PyTorch可以利用GPU加速其数值计算。要在GPU上运行Tensor,在构造张量使用device参数把tensor建立在GPU上。 \n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device（“cuda：0”）＃取消注释以在GPU上运行\n",
    "\n",
    "# N是批量大小; D_in是输入维度;\n",
    "# H是隐藏的维度; D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "#创建随机输入和输出数据\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# 随机初始化权重\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 前向传递：计算预测y\n",
    "    h = x.mm(w1)    #torch类型的点乘\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # 计算和打印损失\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop计算w1和w2相对于损耗的梯度\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # 使用梯度下降更新权重\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 26708958.0\n",
      "1 19818612.0\n",
      "2 18632984.0\n",
      "3 20466468.0\n",
      "4 23426750.0\n",
      "5 25367762.0\n",
      "6 23909830.0\n",
      "7 18945362.0\n",
      "8 12447779.0\n",
      "9 7168574.0\n",
      "10 3877202.5\n",
      "11 2146454.75\n",
      "12 1286013.125\n",
      "13 856368.6875\n",
      "14 628188.1875\n",
      "15 495268.0625\n",
      "16 409016.3125\n",
      "17 347395.15625\n",
      "18 300063.375\n",
      "19 261965.25\n",
      "20 230340.25\n",
      "21 203622.421875\n",
      "22 180792.71875\n",
      "23 161125.875\n",
      "24 144085.796875\n",
      "25 129210.390625\n",
      "26 116176.2890625\n",
      "27 104707.4765625\n",
      "28 94573.5625\n",
      "29 85606.59375\n",
      "30 77643.7265625\n",
      "31 70536.9375\n",
      "32 64194.91796875\n",
      "33 58519.75\n",
      "34 53430.9609375\n",
      "35 48857.8046875\n",
      "36 44737.64453125\n",
      "37 41018.421875\n",
      "38 37657.359375\n",
      "39 34613.1328125\n",
      "40 31852.20703125\n",
      "41 29346.6328125\n",
      "42 27068.00390625\n",
      "43 24991.4765625\n",
      "44 23098.998046875\n",
      "45 21368.392578125\n",
      "46 19784.53515625\n",
      "47 18334.05078125\n",
      "48 17003.171875\n",
      "49 15780.541015625\n",
      "50 14656.783203125\n",
      "51 13622.5205078125\n",
      "52 12669.720703125\n",
      "53 11791.6572265625\n",
      "54 10981.5703125\n",
      "55 10233.2724609375\n",
      "56 9541.435546875\n",
      "57 8901.4931640625\n",
      "58 8309.021484375\n",
      "59 7760.15234375\n",
      "60 7251.263671875\n",
      "61 6779.3271484375\n",
      "62 6340.908203125\n",
      "63 5933.52587890625\n",
      "64 5554.888671875\n",
      "65 5202.7236328125\n",
      "66 4874.96875\n",
      "67 4569.89453125\n",
      "68 4285.5673828125\n",
      "69 4020.5078125\n",
      "70 3773.26318359375\n",
      "71 3542.52099609375\n",
      "72 3327.228515625\n",
      "73 3126.07421875\n",
      "74 2938.17724609375\n",
      "75 2762.35205078125\n",
      "76 2597.8369140625\n",
      "77 2444.1533203125\n",
      "78 2300.332763671875\n",
      "79 2165.62646484375\n",
      "80 2039.4339599609375\n",
      "81 1921.12158203125\n",
      "82 1810.124755859375\n",
      "83 1705.9537353515625\n",
      "84 1608.072998046875\n",
      "85 1516.145263671875\n",
      "86 1429.830322265625\n",
      "87 1348.7672119140625\n",
      "88 1272.5748291015625\n",
      "89 1200.876220703125\n",
      "90 1133.477294921875\n",
      "91 1070.11865234375\n",
      "92 1010.4761962890625\n",
      "93 954.3557739257812\n",
      "94 901.55517578125\n",
      "95 851.8358154296875\n",
      "96 805.0039672851562\n",
      "97 760.8912963867188\n",
      "98 719.3356323242188\n",
      "99 680.1663818359375\n",
      "100 643.2520751953125\n",
      "101 608.4609375\n",
      "102 575.6380615234375\n",
      "103 544.6707153320312\n",
      "104 515.4464111328125\n",
      "105 487.8804016113281\n",
      "106 461.8695373535156\n",
      "107 437.3175048828125\n",
      "108 414.120361328125\n",
      "109 392.22320556640625\n",
      "110 371.5343322753906\n",
      "111 351.9845886230469\n",
      "112 333.5143737792969\n",
      "113 316.0648193359375\n",
      "114 299.57940673828125\n",
      "115 283.98236083984375\n",
      "116 269.239013671875\n",
      "117 255.28897094726562\n",
      "118 242.0908203125\n",
      "119 229.606689453125\n",
      "120 217.80015563964844\n",
      "121 206.62786865234375\n",
      "122 196.05130004882812\n",
      "123 186.03843688964844\n",
      "124 176.56033325195312\n",
      "125 167.58358764648438\n",
      "126 159.08169555664062\n",
      "127 151.03204345703125\n",
      "128 143.4114532470703\n",
      "129 136.18687438964844\n",
      "130 129.34022521972656\n",
      "131 122.85232543945312\n",
      "132 116.70010375976562\n",
      "133 110.87006378173828\n",
      "134 105.34416198730469\n",
      "135 100.10482788085938\n",
      "136 95.1363754272461\n",
      "137 90.42533111572266\n",
      "138 85.95375061035156\n",
      "139 81.71439361572266\n",
      "140 77.69113159179688\n",
      "141 73.87210083007812\n",
      "142 70.25016784667969\n",
      "143 66.8139877319336\n",
      "144 63.55110549926758\n",
      "145 60.451927185058594\n",
      "146 57.511234283447266\n",
      "147 54.718406677246094\n",
      "148 52.06666564941406\n",
      "149 49.54762649536133\n",
      "150 47.15543746948242\n",
      "151 44.88337326049805\n",
      "152 42.725616455078125\n",
      "153 40.677101135253906\n",
      "154 38.72920227050781\n",
      "155 36.87857437133789\n",
      "156 35.119712829589844\n",
      "157 33.447837829589844\n",
      "158 31.857999801635742\n",
      "159 30.347370147705078\n",
      "160 28.910322189331055\n",
      "161 27.5435791015625\n",
      "162 26.244464874267578\n",
      "163 25.008480072021484\n",
      "164 23.832355499267578\n",
      "165 22.71434783935547\n",
      "166 21.64981460571289\n",
      "167 20.637893676757812\n",
      "168 19.67596435546875\n",
      "169 18.761940002441406\n",
      "170 17.891895294189453\n",
      "171 17.062999725341797\n",
      "172 16.274513244628906\n",
      "173 15.523317337036133\n",
      "174 14.808570861816406\n",
      "175 14.12742805480957\n",
      "176 13.47891616821289\n",
      "177 12.861482620239258\n",
      "178 12.273051261901855\n",
      "179 11.712242126464844\n",
      "180 11.178414344787598\n",
      "181 10.66932487487793\n",
      "182 10.183938980102539\n",
      "183 9.721901893615723\n",
      "184 9.281020164489746\n",
      "185 8.860891342163086\n",
      "186 8.460563659667969\n",
      "187 8.079180717468262\n",
      "188 7.715110778808594\n",
      "189 7.368220329284668\n",
      "190 7.03752326965332\n",
      "191 6.721932411193848\n",
      "192 6.421082019805908\n",
      "193 6.134025573730469\n",
      "194 5.860287666320801\n",
      "195 5.598845481872559\n",
      "196 5.349828243255615\n",
      "197 5.1120829582214355\n",
      "198 4.885222911834717\n",
      "199 4.668704032897949\n",
      "200 4.4622368812561035\n",
      "201 4.265076637268066\n",
      "202 4.076794147491455\n",
      "203 3.896960496902466\n",
      "204 3.725374937057495\n",
      "205 3.561762809753418\n",
      "206 3.4057583808898926\n",
      "207 3.256626605987549\n",
      "208 3.113999843597412\n",
      "209 2.9777443408966064\n",
      "210 2.8478009700775146\n",
      "211 2.7235965728759766\n",
      "212 2.605168104171753\n",
      "213 2.4919724464416504\n",
      "214 2.3840527534484863\n",
      "215 2.280416488647461\n",
      "216 2.181894540786743\n",
      "217 2.087491989135742\n",
      "218 1.9971884489059448\n",
      "219 1.9111871719360352\n",
      "220 1.8288792371749878\n",
      "221 1.7501307725906372\n",
      "222 1.6748597621917725\n",
      "223 1.603090524673462\n",
      "224 1.5343561172485352\n",
      "225 1.4688340425491333\n",
      "226 1.4058549404144287\n",
      "227 1.3458542823791504\n",
      "228 1.288464903831482\n",
      "229 1.2336095571517944\n",
      "230 1.1811676025390625\n",
      "231 1.1309666633605957\n",
      "232 1.0829459428787231\n",
      "233 1.0370290279388428\n",
      "234 0.9930794835090637\n",
      "235 0.9511157870292664\n",
      "236 0.9109612703323364\n",
      "237 0.8725484013557434\n",
      "238 0.8357194066047668\n",
      "239 0.8006730675697327\n",
      "240 0.766934335231781\n",
      "241 0.7346305251121521\n",
      "242 0.7038703560829163\n",
      "243 0.674327552318573\n",
      "244 0.6461457014083862\n",
      "245 0.6191473603248596\n",
      "246 0.5932313799858093\n",
      "247 0.5685260891914368\n",
      "248 0.5448423027992249\n",
      "249 0.5221279263496399\n",
      "250 0.5004122853279114\n",
      "251 0.4796029031276703\n",
      "252 0.4596675634384155\n",
      "253 0.44059520959854126\n",
      "254 0.42232340574264526\n",
      "255 0.4048587381839752\n",
      "256 0.38811570405960083\n",
      "257 0.3720369040966034\n",
      "258 0.3567156493663788\n",
      "259 0.3420264422893524\n",
      "260 0.32788485288619995\n",
      "261 0.3144248425960541\n",
      "262 0.30150583386421204\n",
      "263 0.289157509803772\n",
      "264 0.27727800607681274\n",
      "265 0.26589930057525635\n",
      "266 0.25504884123802185\n",
      "267 0.24460767209529877\n",
      "268 0.23461377620697021\n",
      "269 0.2249702662229538\n",
      "270 0.2157800793647766\n",
      "271 0.20701056718826294\n",
      "272 0.19858276844024658\n",
      "273 0.1905418485403061\n",
      "274 0.18279290199279785\n",
      "275 0.17535127699375153\n",
      "276 0.16825266182422638\n",
      "277 0.16142141819000244\n",
      "278 0.15487615764141083\n",
      "279 0.1486145704984665\n",
      "280 0.14259746670722961\n",
      "281 0.13681800663471222\n",
      "282 0.13127686083316803\n",
      "283 0.12598879635334015\n",
      "284 0.12092369049787521\n",
      "285 0.11607065796852112\n",
      "286 0.1113765612244606\n",
      "287 0.10688020288944244\n",
      "288 0.10261988639831543\n",
      "289 0.09848274290561676\n",
      "290 0.09455384314060211\n",
      "291 0.09074559062719345\n",
      "292 0.08711479604244232\n",
      "293 0.08366444706916809\n",
      "294 0.08031068742275238\n",
      "295 0.07707442343235016\n",
      "296 0.07402604073286057\n",
      "297 0.07107982039451599\n",
      "298 0.0682351142168045\n",
      "299 0.0655326396226883\n",
      "300 0.06291753053665161\n",
      "301 0.060427408665418625\n",
      "302 0.05802180990576744\n",
      "303 0.055738601833581924\n",
      "304 0.05353586748242378\n",
      "305 0.05142468586564064\n",
      "306 0.04937620833516121\n",
      "307 0.04741436988115311\n",
      "308 0.04554696008563042\n",
      "309 0.043743208050727844\n",
      "310 0.04201854020357132\n",
      "311 0.04037429019808769\n",
      "312 0.0387825071811676\n",
      "313 0.03725653886795044\n",
      "314 0.035787906497716904\n",
      "315 0.03438378870487213\n",
      "316 0.03303328901529312\n",
      "317 0.031735166907310486\n",
      "318 0.03049747459590435\n",
      "319 0.029310250654816628\n",
      "320 0.028165476396679878\n",
      "321 0.027062276378273964\n",
      "322 0.02601558156311512\n",
      "323 0.025002414360642433\n",
      "324 0.024030450731515884\n",
      "325 0.023088540881872177\n",
      "326 0.022185642272233963\n",
      "327 0.021320611238479614\n",
      "328 0.020501848310232162\n",
      "329 0.019712382927536964\n",
      "330 0.018945669755339622\n",
      "331 0.01821197010576725\n",
      "332 0.017504040151834488\n",
      "333 0.016834154725074768\n",
      "334 0.016191450878977776\n",
      "335 0.01557623315602541\n",
      "336 0.014970222488045692\n",
      "337 0.014391012489795685\n",
      "338 0.013844886794686317\n",
      "339 0.013313121162354946\n",
      "340 0.01280366163700819\n",
      "341 0.012312155216932297\n",
      "342 0.011847610585391521\n",
      "343 0.011405730620026588\n",
      "344 0.010974385775625706\n",
      "345 0.010556572116911411\n",
      "346 0.010161700658500195\n",
      "347 0.009774151258170605\n",
      "348 0.009409086778759956\n",
      "349 0.009057139046490192\n",
      "350 0.00871853344142437\n",
      "351 0.008391182869672775\n",
      "352 0.00808061845600605\n",
      "353 0.007778744213283062\n",
      "354 0.007487115450203419\n",
      "355 0.007214538753032684\n",
      "356 0.006950634066015482\n",
      "357 0.006697938311845064\n",
      "358 0.006450001150369644\n",
      "359 0.006210659630596638\n",
      "360 0.005987097043544054\n",
      "361 0.005768539384007454\n",
      "362 0.005559861660003662\n",
      "363 0.005357560236006975\n",
      "364 0.005167558789253235\n",
      "365 0.004978714976459742\n",
      "366 0.004801634233444929\n",
      "367 0.004629043396562338\n",
      "368 0.004465131089091301\n",
      "369 0.0043035466223955154\n",
      "370 0.004148409701883793\n",
      "371 0.004005760885775089\n",
      "372 0.003864411963149905\n",
      "373 0.0037296698428690434\n",
      "374 0.003602302633225918\n",
      "375 0.003478135447949171\n",
      "376 0.003357197158038616\n",
      "377 0.0032419608905911446\n",
      "378 0.003129458287730813\n",
      "379 0.003020740579813719\n",
      "380 0.0029230795335024595\n",
      "381 0.0028244208078831434\n",
      "382 0.002730530919507146\n",
      "383 0.00263769063167274\n",
      "384 0.002552564488723874\n",
      "385 0.00246902322396636\n",
      "386 0.0023855248000472784\n",
      "387 0.0023082380648702383\n",
      "388 0.0022313976660370827\n",
      "389 0.0021564376074820757\n",
      "390 0.002086317865177989\n",
      "391 0.002021520398557186\n",
      "392 0.0019562130328267813\n",
      "393 0.0018932085949927568\n",
      "394 0.0018333916086703539\n",
      "395 0.0017776192398741841\n",
      "396 0.0017221028683707118\n",
      "397 0.0016675952356308699\n",
      "398 0.0016177596990019083\n",
      "399 0.0015671330038458109\n",
      "400 0.0015181333292275667\n",
      "401 0.0014697621809318662\n",
      "402 0.0014273866545408964\n",
      "403 0.001384166651405394\n",
      "404 0.0013416423462331295\n",
      "405 0.0013015307486057281\n",
      "406 0.0012622434878721833\n",
      "407 0.0012261552037671208\n",
      "408 0.0011902611004188657\n",
      "409 0.001155305071733892\n",
      "410 0.0011206858325749636\n",
      "411 0.0010891390265896916\n",
      "412 0.001056839362718165\n",
      "413 0.001027437625452876\n",
      "414 0.000997399678453803\n",
      "415 0.0009695453918538988\n",
      "416 0.0009430657373741269\n",
      "417 0.0009160884656012058\n",
      "418 0.0008908548625186086\n",
      "419 0.0008679686579853296\n",
      "420 0.0008437592186965048\n",
      "421 0.0008199417497962713\n",
      "422 0.000797040353063494\n",
      "423 0.0007751244120299816\n",
      "424 0.000754956912714988\n",
      "425 0.0007356912828981876\n",
      "426 0.0007161684916354716\n",
      "427 0.0006981698679737747\n",
      "428 0.0006781464908272028\n",
      "429 0.0006618678453378379\n",
      "430 0.000644722837023437\n",
      "431 0.0006281942478381097\n",
      "432 0.0006113866111263633\n",
      "433 0.0005966690951026976\n",
      "434 0.0005826113047078252\n",
      "435 0.0005670046084560454\n",
      "436 0.0005528957699425519\n",
      "437 0.0005403545801527798\n",
      "438 0.0005262056365609169\n",
      "439 0.0005142742884345353\n",
      "440 0.0005017854273319244\n",
      "441 0.0004893411532975733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 0.00047864069347269833\n",
      "443 0.0004668429319281131\n",
      "444 0.0004550816083792597\n",
      "445 0.00044408865505829453\n",
      "446 0.0004348561051301658\n",
      "447 0.0004241667629685253\n",
      "448 0.0004145086568314582\n",
      "449 0.0004053988086525351\n",
      "450 0.0003962661139667034\n",
      "451 0.00038758799200877547\n",
      "452 0.00037904217606410384\n",
      "453 0.0003693429462146014\n",
      "454 0.0003613020235206932\n",
      "455 0.00035353098064661026\n",
      "456 0.00034559896448627114\n",
      "457 0.00033805702696554363\n",
      "458 0.0003310505417175591\n",
      "459 0.0003232513554394245\n",
      "460 0.00031684068380855024\n",
      "461 0.00030962988967075944\n",
      "462 0.00030325594707392156\n",
      "463 0.00029770610854029655\n",
      "464 0.00029126848676241934\n",
      "465 0.0002862136752810329\n",
      "466 0.0002796488697640598\n",
      "467 0.00027389617753215134\n",
      "468 0.0002683783241081983\n",
      "469 0.00026308302767574787\n",
      "470 0.00025745161110535264\n",
      "471 0.00025259278481826186\n",
      "472 0.0002476144290994853\n",
      "473 0.0002422044926788658\n",
      "474 0.00023759121540933847\n",
      "475 0.00023299964959733188\n",
      "476 0.00022875447757542133\n",
      "477 0.00022380921291187406\n",
      "478 0.00021959812147542834\n",
      "479 0.00021515700791496783\n",
      "480 0.00021086574997752905\n",
      "481 0.0002071555791189894\n",
      "482 0.00020283825870137662\n",
      "483 0.00019876791338901967\n",
      "484 0.00019531518046278507\n",
      "485 0.00019121557124890387\n",
      "486 0.00018747815920505673\n",
      "487 0.0001839300530264154\n",
      "488 0.0001810094399843365\n",
      "489 0.00017759145703166723\n",
      "490 0.0001744308101478964\n",
      "491 0.00017134679364971817\n",
      "492 0.0001677485997788608\n",
      "493 0.0001650036429055035\n",
      "494 0.0001620100811123848\n",
      "495 0.00015924892795737833\n",
      "496 0.00015629525296390057\n",
      "497 0.0001539497752673924\n",
      "498 0.00015100397286005318\n",
      "499 0.00014834666217211634\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device（“cuda：0”）＃取消注释以在GPU上运行\n",
    "\n",
    "# N是批量大小; D_in是输入维度;\n",
    "# H是隐藏的维度; D_out是输出维度。\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# 创建随机Tensors以保持输入和输出。\n",
    "# 设置requires_grad = False表示我们不需要计算渐变\n",
    "# 在向后传球期间对于这些Tensors。\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# 为权重创建随机Tensors。\n",
    "# 设置requires_grad = True表示我们想要计算渐变\n",
    "# 在向后传球期间尊重这些张贴。\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # 前向传播：使用tensors上的操作计算预测值y; \n",
    "      # 由于w1和w2有requires_grad=True，涉及这些张量的操作将让PyTorch构建计算图，\n",
    "    # 从而允许自动计算梯度。由于我们不再手工实现反向传播，所以不需要保留中间值的引用。\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # 使用Tensors上的操作计算和打印丢失。\n",
    "    # loss是一个形状为()的张量\n",
    "    # loss.item() 得到这个张量对应的python数值\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # 使用autograd计算反向传播。这个调用将计算loss对所有requires_grad=True的tensor的梯度。\n",
    "    # 这次调用后，w1.grad和w2.grad将分别是loss对w1和w2的梯度张量。\n",
    "    loss.backward()\n",
    "\n",
    "    # 使用梯度下降更新权重。对于这一步，我们只想对w1和w2的值进行原地改变；不想为更新阶段构建计算图，\n",
    "    # 所以我们使用torch.no_grad()上下文管理器防止PyTorch为更新构建计算图\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # 反向传播后手动将梯度设置为零\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
